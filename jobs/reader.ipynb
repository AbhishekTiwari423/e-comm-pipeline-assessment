{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c883f75b-ae85-4cde-9ded-90a6a86ab347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "class Reader:\n",
    "    \"\"\"\n",
    "    Module responsible reading data based on file format and other parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, spark: SparkSession):\n",
    "        self.spark = spark\n",
    "\n",
    "    def read_csv(self, path: str, header: bool, schema: StructType = None):\n",
    "        \"\"\"\n",
    "        Reads CSV data with optional schema.\n",
    "\n",
    "        Parameters:\n",
    "        path (str): Path to CSV file or directory\n",
    "        header (bool): Whether CSV has header row\n",
    "        schema (StructType, optional): Schema to enforce while reading CSV\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: PySpark DataFrame\n",
    "\n",
    "        Raises:\n",
    "        TypeError: If 'header' is not boolean or schema is wrong type\n",
    "        FileNotFoundError: If path does not exist\n",
    "        Py4JJavaError: For general Spark errors\n",
    "        Exception: For other unexpected errors\n",
    "        \"\"\"\n",
    "        if not isinstance(header, bool):\n",
    "            raise TypeError(\"The 'header' parameter must be a boolean (True or False).\")\n",
    "\n",
    "        try:\n",
    "            reader = self.spark.read.format(\"csv\").option(\"header\", header)\n",
    "\n",
    "            if schema is not None:\n",
    "                if not isinstance(schema, StructType):\n",
    "                    raise TypeError(\"The 'schema' parameter must be a StructType when provided.\")\n",
    "                reader = reader.schema(schema)\n",
    "            else:\n",
    "                # Infer schema if not provided\n",
    "                reader = reader.option(\"inferSchema\", True)\n",
    "\n",
    "            return reader.load(path)\n",
    "\n",
    "        except AnalysisException as e:\n",
    "            if \"path does not exist\" in str(e).lower():\n",
    "                raise FileNotFoundError(f\"File or directory not found at path: '{path}'\")\n",
    "            raise Py4JJavaError(f\"A PySpark AnalysisException occurred while reading the CSV: {e}\")\n",
    "\n",
    "        except Py4JJavaError as e:\n",
    "            raise Py4JJavaError(f\"A general PySpark error occurred while reading the CSV: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
    "\n",
    "    def read_excel(self, path: str, header: bool, schema: StructType = None):\n",
    "        \"\"\"\n",
    "        Reads Excel data into a PySpark DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        path (str): Path to the Excel file.\n",
    "        header (bool): Whether the first row is a header.\n",
    "        schema (StructType, optional): Schema for the DataFrame. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: Loaded DataFrame.\n",
    "\n",
    "        Raises:\n",
    "        TypeError: If 'header' is not boolean.\n",
    "        FileNotFoundError: If the file does not exist at the given path.\n",
    "        Exception: For other unexpected errors.\n",
    "        \"\"\"\n",
    "        if not isinstance(header, bool):\n",
    "            raise TypeError(\"The 'header' parameter must be a boolean (True or False).\")\n",
    "\n",
    "        try:\n",
    "            reader = self.spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "                                    .option(\"header\", header)\n",
    "\n",
    "            # Apply schema only if provided\n",
    "            if schema is not None:\n",
    "                reader = reader.schema(schema)\n",
    "\n",
    "            return reader.load(path)\n",
    "\n",
    "        except AnalysisException as e:\n",
    "            if \"path does not exist\" in str(e).lower():\n",
    "                raise FileNotFoundError(f\"File or directory not found at path: '{path}'\")\n",
    "            raise Exception(f\"A PySpark AnalysisException occurred while reading the Excel: {e}\")\n",
    "\n",
    "        except Py4JJavaError as e:\n",
    "            raise Exception(f\"A general PySpark error occurred while reading the Excel: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An unexpected error occurred while reading the Excel: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    def read_json(self, path: str, multiLine: bool, schema: StructType = None):\n",
    "        \"\"\"\n",
    "        Reads JSON data into a PySpark DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        path (str): Path to the JSON file.\n",
    "        multiLine (bool): Whether JSON is multi-line.\n",
    "        schema (StructType, optional): Schema for the DataFrame. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: Loaded DataFrame.\n",
    "\n",
    "        Raises:\n",
    "        TypeError: If 'multiLine' is not boolean.\n",
    "        FileNotFoundError: If the file does not exist at the given path.\n",
    "        Exception: For other unexpected errors.\n",
    "        \"\"\"\n",
    "        if not isinstance(multiLine, bool):\n",
    "            raise TypeError(\"The 'multiLine' parameter must be a boolean (True or False).\")\n",
    "\n",
    "        try:\n",
    "            reader = self.spark.read.format(\"json\") \\\n",
    "                                    .option(\"multiLine\", multiLine)\n",
    "\n",
    "            # Apply schema only if provided\n",
    "            if schema is not None:\n",
    "                reader = reader.schema(schema)\n",
    "\n",
    "            return reader.load(path)\n",
    "\n",
    "        except AnalysisException as e:\n",
    "            if \"path does not exist\" in str(e).lower():\n",
    "                raise FileNotFoundError(f\"File or directory not found at path: '{path}'\")\n",
    "            raise Exception(f\"A PySpark AnalysisException occurred while reading the JSON: {e}\")\n",
    "\n",
    "        except Py4JJavaError as e:\n",
    "            raise Exception(f\"A general PySpark error occurred while reading the JSON: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An unexpected error occurred while reading the JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7478b915-b0c1-4291-920c-678726ee325e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "reader",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}