{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b13e40e5-3dd0-46c1-bf0c-c67a068f1c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../jobs/reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd1ddb08-5fc2-4928-8cf5-20453b5360ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../jobs/data_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ac69fb-88e5-458c-80fa-3f61c705512e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../jobs/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e0104bb-60e8-4a34-ad25-c1f187cd9218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../jobs/aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f39f3c-9a89-47e1-9be5-bb6f4172c45c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../jobs/utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a4ca5aa-ec1a-4f70-8f72-b0a2b7725ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 58712), raddr=('127.0.0.1', 43139)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n/usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 58132), raddr=('127.0.0.1', 40831)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n.../usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 33144), raddr=('127.0.0.1', 37331)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 50740), raddr=('127.0.0.1', 42329)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 53156), raddr=('127.0.0.1', 33747)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 48628), raddr=('127.0.0.1', 39149)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n/usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 52486), raddr=('127.0.0.1', 35573)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n../usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 53650), raddr=('127.0.0.1', 39039)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n/usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 50174), raddr=('127.0.0.1', 38673)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 55130), raddr=('127.0.0.1', 41275)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 52868), raddr=('127.0.0.1', 35407)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n.../usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 60924), raddr=('127.0.0.1', 42777)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n."
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_year_category_query\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 56376), raddr=('127.0.0.1', 36037)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n./usr/lib/python3.11/socket.py:789: ResourceWarning: unclosed <socket.socket fd=81, family=2, type=1, proto=6, laddr=('127.0.0.1', 46570), raddr=('127.0.0.1', 41191)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\n.\n----------------------------------------------------------------------\nRan 16 tests in 63.368s\n\nOK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "class TestUtility(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = (\n",
    "            SparkSession.builder\n",
    "            .appName(\"test_utility\")\n",
    "            .getOrCreate()\n",
    "        )\n",
    "        cls.utility = Utility(cls.spark)\n",
    "        cls.aggregator = Aggregator(cls.spark)\n",
    "        cls.transformer = Transformer(cls.spark)\n",
    "\n",
    "        # create a reusable test dataframe\n",
    "        data = [(\"1\", \"Abhi\"), (\"2\", \"Shashi\")]\n",
    "        columns = [\"id\", \"name\"]\n",
    "        cls.df = cls.spark.createDataFrame(data, columns)\n",
    "\n",
    "        test_data_path = \"dbfs:/FileStore/Mock/customer_sample_mock.csv\"\n",
    "        cls.enrich_df = cls.spark.read.option(\"inferSchema\", True).csv(test_data_path, header=True)\n",
    "\n",
    "        data = [\n",
    "            (2020, \"Electronics\", 101, \"Alice\", 100.125),\n",
    "            (2020, \"Clothing\",   102, \"Bob\",   200.456),\n",
    "            (2021, \"Electronics\", 101, \"Alice\", 300.789),\n",
    "            (2021, \"Clothing\",   102, \"Bob\",   400.111),\n",
    "        ]\n",
    "        cls.test_df = cls.spark.createDataFrame(\n",
    "            data, [\"year\", \"category\", \"customer_id\", \"customer_name\", \"profit\"]\n",
    "        )\n",
    "        cls.test_df.createOrReplaceTempView(\"enriched_test\")\n",
    "\n",
    "\n",
    "    def sample_data_enrich(self):\n",
    "        orders = [\n",
    "            # Alice's orders\n",
    "            (1001, date(2022, 5, 1), date(2022, 5, 5), 1, 101, 123.456),\n",
    "            (1002, date(2023, 3, 15), date(2023, 3, 20), 1, 101, 300.111),\n",
    "            (1003, date(2024, 4, 1), date(2024, 4, 7), 1, 104, 850.777),\n",
    "\n",
    "            # Bob's orders\n",
    "            (1004, date(2022, 6, 2), date(2022, 6, 10), 2, 102, 456.789),\n",
    "            (1005, date(2024, 1, 10), date(2024, 1, 15), 2, 102, 250.499),\n",
    "\n",
    "            # Charlie's order\n",
    "            (1006, date(2023, 7, 18), date(2023, 7, 25), 3, 103, 789.555),\n",
    "\n",
    "            # Diana's order\n",
    "            (1007, date(2024, 2, 5), date(2024, 2, 12), 4, 104, 999.999),\n",
    "        ]\n",
    "\n",
    "        customers = [\n",
    "            (1, \"Alice\", \"USA\"),\n",
    "            (2, \"Bob\", \"India\"),\n",
    "            (3, \"Charlie\", \"UK\"),\n",
    "            (4, \"Diana\", \"Germany\"),\n",
    "        ]\n",
    "\n",
    "        products = [\n",
    "            (101, \"Electronics\", \"Mobile\"),\n",
    "            (102, \"Clothing\", \"Shirts\"),\n",
    "            (103, \"Furniture\", \"Chairs\"),\n",
    "            (104, \"Electronics\", \"Laptop\"),\n",
    "        ]\n",
    "\n",
    "        orders_df = self.spark.createDataFrame(\n",
    "            orders, [\"order_id\", \"order_date\", \"ship_date\", \"customer_id\", \"product_id\", \"profit\"]\n",
    "        )\n",
    "        customers_df = self.spark.createDataFrame(\n",
    "            customers, [\"customer_id\", \"customer_name\", \"country\"]\n",
    "        )\n",
    "        products_df = self.spark.createDataFrame(\n",
    "            products, [\"product_id\", \"category\", \"sub_category\"]\n",
    "        )\n",
    "\n",
    "        return orders_df, customers_df, products_df\n",
    "    \n",
    "    #============ Task 1 test cases ==========================================\n",
    "    \n",
    "    def test_create_raw_table_exist(self):\n",
    "        \"\"\"\n",
    "        Validates table existence after creation\n",
    "        \"\"\"\n",
    "        table_name = self.utility.create_delta_table(self.df, \"test_table1\")\n",
    "        tables = [t.name for t in spark.catalog.listTables()]\n",
    "        assert table_name in tables\n",
    "\n",
    "    def test_create_raw_table(self):\n",
    "        \"\"\"\n",
    "        Tests if table is a delta table\n",
    "        \"\"\"\n",
    "        table_name = self.utility.create_delta_table(self.df, \"test_table2\")\n",
    "        delta_tbl = DeltaTable.forName(self.spark, table_name)\n",
    "        self.assertIsNotNone(delta_tbl)\n",
    "\n",
    "    def test_table_schema(self):\n",
    "        \"\"\"\n",
    "        Tests schema of the table created\n",
    "        \"\"\"\n",
    "        table_name = self.utility.create_delta_table(self.df, \"test_table3\")\n",
    "        schema_fields = [f.name for f in self.spark.table(table_name).schema.fields]\n",
    "        self.assertListEqual(schema_fields, [\"id\", \"name\"])\n",
    "\n",
    "    def test_table_data_count(self):\n",
    "        \"\"\"\n",
    "        Tests record count of table created\n",
    "        \"\"\"\n",
    "        table_name = self.utility.create_delta_table(self.df, \"test_table3\")\n",
    "        row_count = self.spark.table(table_name).count()\n",
    "        self.assertEqual(row_count, 2)\n",
    "\n",
    "    # ================Task:2 test cases =================================== \n",
    "    def sample_data_enrich2(self):\n",
    "        # Customers\n",
    "        customers = [\n",
    "            (1, \"Alice\", \"alice@mail.com\", \"111\", \"Addr1\", \"Consumer\", \"USA\", \"New York\", \"NY\", \"10001\", \"East\"),\n",
    "            (2, \"Bob\", \"bob@mail.com\", \"222\", \"Addr2\", \"Corporate\", \"USA\", \"Los Angeles\", \"CA\", \"90001\", \"West\"),\n",
    "            (3, \"Charlie\", \"charlie@mail.com\", \"333\", \"Addr3\", \"Home Office\", \"USA\", \"Chicago\", \"IL\", \"60007\", \"Central\")\n",
    "        ]\n",
    "        customers_df = self.spark.createDataFrame(customers, \n",
    "            [\"customer_id\", \"customer_name\", \"email\", \"phone\", \"address\", \n",
    "            \"segment\", \"country\", \"city\", \"state\", \"postal_code\", \"region\"])\n",
    "\n",
    "        # Products\n",
    "        products = [\n",
    "            (101, \"Furniture\", \"Chairs\", \"Office Chair\", \"NY\", 120.0),\n",
    "            (102, \"Technology\", \"Phones\", \"iPhone\", \"CA\", 999.0),\n",
    "            (103, \"Office Supplies\", \"Paper\", \"A4 Paper\", \"IL\", 10.0)\n",
    "        ]\n",
    "        products_df = self.spark.createDataFrame(products, \n",
    "            [\"product_id\", \"category\", \"sub_category\", \"product_name\", \"state\", \"price_per_product\"])\n",
    "\n",
    "        # Orders (with REPEATED purchases)\n",
    "        orders = [\n",
    "            # Alice orders multiple times\n",
    "            (1001, date(2023,1,1), date(2023,1,5), \"Second Class\", 1, 101, 2, 120.0, 10.0, 30.0),   # Office Chair\n",
    "            (1002, date(2023,1,2), date(2023,1,6), \"First Class\", 1, 102, 1, 999.0, 50.0, 200.0),   # iPhone\n",
    "            (1005, date(2023,3,1), date(2023,3,5), \"Standard\", 1, 103, 5, 10.0, 2.0, 5.0),          # A4 Paper\n",
    "            (1006, date(2023,3,10), date(2023,3,15), \"Standard\", 1, 101, 1, 120.0, 0.0, 15.0),      # Office Chair again\n",
    "\n",
    "            # Bob orders the same product twice\n",
    "            (1003, date(2023,2,1), date(2023,2,3), \"Standard\", 2, 103, 10, 10.0, 0.0, 20.0),        # A4 Paper\n",
    "            (1007, date(2023,2,15), date(2023,2,18), \"Second Class\", 2, 103, 15, 10.0, 1.0, 30.0), # A4 Paper again\n",
    "\n",
    "            # Charlie orders once\n",
    "            (1004, date(2023,2,5), date(2023,2,8), \"Second Class\", 3, 101, 1, 120.0, 0.0, 15.0),   # Office Chair\n",
    "        ]\n",
    "        orders_df = self.spark.createDataFrame(orders, \n",
    "            [\"order_id\", \"order_date\", \"ship_date\", \"ship_mode\", \"customer_id\", \n",
    "            \"product_id\", \"quantity\", \"price\", \"discount\", \"profit\"])\n",
    "\n",
    "        return customers_df, orders_df, products_df\n",
    "        \n",
    "    def test_enriched_customer_table(self):\n",
    "        customers_df, orders_df, products_df = self.sample_data_enrich2()\n",
    "        \n",
    "        enriched_customers = self.transformer.create_enriched_customer_table(customers_df, orders_df, products_df)\n",
    "\n",
    "        # Ensure enrichment columns exist\n",
    "        assert \"total_orders\" in enriched_customers.columns\n",
    "        assert \"fav_category\" in enriched_customers.columns\n",
    "        \n",
    "        # Fetch Alice’s metrics (customer_id=1)\n",
    "        alice = enriched_customers.filter(\"customer_id = 1\").collect()[0]\n",
    "        assert alice.total_orders == 4        # Alice has 4 orders total\n",
    "        assert alice.total_quantity == 9      # Quantities: 2 + 1 + 5 + 1\n",
    "        assert alice.fav_category == \"Furniture\"  # Alice bought Office Chair twice\n",
    "\n",
    "        # Fetch Bob’s metrics (customer_id=2)\n",
    "        bob = enriched_customers.filter(\"customer_id = 2\").collect()[0]\n",
    "        assert bob.total_orders == 2          # Bob has 2 orders\n",
    "        assert bob.total_quantity == 25       # Quantities: 10 + 15\n",
    "        assert bob.fav_sub_category == \"Paper\"  # Both orders are A4 Paper\n",
    "\n",
    "    def test_enriched_product_table(self):\n",
    "        customers_df, orders_df, products_df = self.sample_data_enrich2()\n",
    "        \n",
    "        enriched_products = self.transformer.create_enriched_product_table(customers_df, orders_df, products_df)\n",
    "\n",
    "        # Ensure enrichment columns exist\n",
    "        assert \"total_orders\" in enriched_products.columns\n",
    "        assert \"best_region\" in enriched_products.columns\n",
    "        \n",
    "        # Fetch Office Chair metrics (product_id=101)\n",
    "        chair = enriched_products.filter(\"product_id = 101\").collect()[0]\n",
    "        assert chair.total_orders == 3            # Alice(2) + Charlie(1)\n",
    "        assert chair.total_quantity_sold == 4     # Quantities: 2 + 1 + 1\n",
    "        assert chair.best_region == \"East\"        # Alice from East bought most\n",
    "\n",
    "        # Fetch Paper metrics (product_id=103)\n",
    "        paper = enriched_products.filter(\"product_id = 103\").collect()[0]\n",
    "        assert paper.total_orders == 3            # Bob(2) +  Alice(1)\n",
    "        assert paper.total_quantity_sold == 30    # Quantities: 5 (Alice) + 10 + 15 (Bob)\n",
    "        assert paper.distinct_customers ==  2     # Alice & Bob both bought Paper\n",
    "\n",
    "\n",
    "    # ================Task:3 test cases =================================== \n",
    "    def test_enriched_orders_rowcount(self):\n",
    "        orders, customers, products = self.sample_data_enrich()\n",
    "        enriched = self.transformer.enrich_orders(orders, customers, products)\n",
    "        self.assertEqual(enriched.count(), 7)  # 7 total orders\n",
    "\n",
    "    def test_profit_rounding(self):\n",
    "        orders, customers, products = self.sample_data_enrich()\n",
    "        enriched = self.transformer.enrich_orders(orders, customers, products)\n",
    "        profits = {row.order_id: row.profit for row in enriched.collect()}\n",
    "        self.assertEqual(profits[1001], 123.46)\n",
    "        self.assertEqual(profits[1004], 456.79)\n",
    "        self.assertEqual(profits[1007], 1000.00)\n",
    "\n",
    "    def test_groupby_year_total_profit(self):\n",
    "        orders, customers, products = self.sample_data_enrich()\n",
    "        enriched = self.transformer.enrich_orders(orders, customers, products)\n",
    "        yearly = (enriched.groupBy(\"year\")\n",
    "                  .agg(F.round(F.sum(\"profit\"), 2).alias(\"total_profit\"))\n",
    "                  .orderBy(\"year\"))\n",
    "        result = [(r[\"year\"], r[\"total_profit\"]) for r in yearly.collect()]\n",
    "        expected = [\n",
    "            (2022, 580.25),   # 123.46 (Alice) + 456.79 (Bob)\n",
    "            (2023, 1089.67),  # 300.11 (Alice) + 789.56 (Charlie)\n",
    "            (2024, 2101.28),  # 850.78 (Alice) + 250.50 (Bob) + 1000.00 (Diana)\n",
    "        ]\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "    def test_customer_order_counts(self):\n",
    "        orders, customers, products = self.sample_data_enrich()\n",
    "        enriched = self.transformer.enrich_orders(orders, customers, products)\n",
    "        counts = (enriched.groupBy(\"customer_name\")\n",
    "                           .count()\n",
    "                           .orderBy(\"customer_name\"))\n",
    "        result = {r[\"customer_name\"]: r[\"count\"] for r in counts.collect()}\n",
    "        expected = {\n",
    "            \"Alice\": 3,   # 3 orders across years\n",
    "            \"Bob\": 2,\n",
    "            \"Charlie\": 1,\n",
    "            \"Diana\": 1,\n",
    "        }\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "    def test_distinct_categories(self):\n",
    "        orders, customers, products = self.sample_data_enrich()\n",
    "        enriched = self.transformer.enrich_orders(orders, customers, products)\n",
    "        categories = {row.category for row in enriched.select(\"category\").distinct().collect()}\n",
    "        expected = {\"Electronics\", \"Clothing\", \"Furniture\"}\n",
    "        self.assertEqual(categories, expected)\n",
    "\n",
    "    # ================Task:4 test cases ===================================\n",
    "    def test_aggregate_with_query_year(self):\n",
    "        agg_data = self.aggregator.aggregate_profit(self.enrich_df)\n",
    "        cust1 = agg_data.filter( (col(\"customer_id\")==1) & (col(\"year\")==2025))\n",
    "        cust2 = agg_data.filter( (col(\"customer_id\")==2) & (col(\"year\")==2024))\n",
    "        row = cust1.collect()[0].asDict()\n",
    "        row2 = cust2.collect()[0].asDict()\n",
    "        self.assertEqual(cust1.count(),1)\n",
    "        self.assertEqual(row[\"year\"], 2025)\n",
    "        self.assertEqual(row[\"category\"], \"furniture\")\n",
    "        self.assertEqual(row[\"Sub_Category\"],\"chair\")\n",
    "        self.assertEqual(row[\"customer_name\"], \"Abhi\")\n",
    "        self.assertEqual(row[\"profit_sum\"],60)\n",
    "        self.assertEqual(row2[\"profit_sum\"],50)\n",
    "\n",
    "    #=============== Task:5 test cases ================================== \n",
    "    def test_year_query(self):\n",
    "        query = \"\"\"\n",
    "            SELECT year, ROUND(SUM(profit),2) AS total_profit\n",
    "            FROM enriched_test\n",
    "            GROUP BY year\n",
    "            ORDER BY year\n",
    "        \"\"\"\n",
    "        result = self.aggregator.aggregate_with_query(query).collect()\n",
    "        result_dict = {row[\"year\"]: row[\"total_profit\"] for row in result}\n",
    "\n",
    "        assert result_dict[2020] == 300.58  # 100.125 + 200.456\n",
    "        assert result_dict[2021] == 700.90  # 300.789 + 400.111\n",
    "        assert len(result_dict) == 2\n",
    "\n",
    "    def test_year_category_query(self):\n",
    "        query = \"\"\"\n",
    "            SELECT year, category, ROUND(SUM(profit),2) AS total_profit\n",
    "            FROM enriched_test\n",
    "            GROUP BY year, category\n",
    "            ORDER BY year\n",
    "        \"\"\"\n",
    "        result = self.aggregator.aggregate_with_query(query).collect()\n",
    "        result_dict = {(row[\"year\"], row[\"category\"]): row[\"total_profit\"] for row in result}\n",
    "        print(\"test_year_category_query\")\n",
    "        assert result_dict[(2020, \"Electronics\")] == 100.13\n",
    "        assert result_dict[(2020, \"Clothing\")] == 200.46\n",
    "        assert result_dict[(2021, \"Electronics\")] == 300.79\n",
    "        assert result_dict[(2021, \"Clothing\")] == 400.11\n",
    "        assert len(result_dict) == 4\n",
    "\n",
    "    def test_customer_query(self):\n",
    "        query = \"\"\"\n",
    "            SELECT customer_id, customer_name, ROUND(SUM(profit),2) AS total_profit\n",
    "            FROM enriched_test\n",
    "            GROUP BY customer_id, customer_name\n",
    "        \"\"\"\n",
    "        result = self.aggregator.aggregate_with_query(query).collect()\n",
    "        result_dict = {(row[\"customer_id\"], row[\"customer_name\"]): row[\"total_profit\"] for row in result}\n",
    "\n",
    "        assert result_dict[(101, \"Alice\")] == 400.91  # 100.125 + 300.789\n",
    "        assert result_dict[(102, \"Bob\")] == 600.57    # 200.456 + 400.111\n",
    "        assert len(result_dict) == 2\n",
    "\n",
    "    def test_year_customer_query(self):\n",
    "        query = \"\"\"\n",
    "            SELECT year, customer_id, customer_name, ROUND(SUM(profit),2) AS total_profit\n",
    "            FROM enriched_test\n",
    "            GROUP BY year, customer_id, customer_name\n",
    "            ORDER BY year\n",
    "        \"\"\"\n",
    "        result = self.aggregator.aggregate_with_query(query).collect()\n",
    "        result_dict = {(row[\"year\"], row[\"customer_id\"], row[\"customer_name\"]): row[\"total_profit\"] for row in result}\n",
    "\n",
    "        assert result_dict[(2020, 101, \"Alice\")] == 100.13\n",
    "        assert result_dict[(2020, 102, \"Bob\")] == 200.46\n",
    "        assert result_dict[(2021, 101, \"Alice\")] == 300.79\n",
    "        assert result_dict[(2021, 102, \"Bob\")] == 400.11\n",
    "        assert len(result_dict) == 4\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_metrics",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}